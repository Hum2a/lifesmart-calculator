name: 🚀 Performance Monitoring

on:
  schedule:
    # Run performance checks daily at 4 AM UTC
    - cron: "0 4 * * *"
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

env:
  NODE_VERSION: "18"

jobs:
  # 📊 Lighthouse Performance
  lighthouse:
    name: 📊 Lighthouse Performance
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🏗️ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline

      - name: 🏗️ Build project
        run: npm run build

      - name: 🚀 Start application
        run: |
          echo "🚀 Starting application for performance testing..."
          npx serve -s build -l 3000 &
          sleep 15
          curl -f http://localhost:3000 || exit 1

      - name: 📊 Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v10
        with:
          configPath: "./.lighthouserc.json"
          uploadArtifacts: true
          temporaryPublicStorage: true
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
        continue-on-error: true

      - name: 📈 Generate Lighthouse report
        run: |
          echo "📈 Generating detailed Lighthouse report..."
          npx lighthouse http://localhost:3000 --output=html --output-path=./lighthouse-report.html --chrome-flags="--headless"
        continue-on-error: true

      - name: 📤 Upload Lighthouse report
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-report-${{ github.sha }}
          path: lighthouse-report.html
          retention-days: 30

  # 📏 Bundle Size Analysis
  bundle-analysis:
    name: 📏 Bundle Size Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🏗️ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline

      - name: 🏗️ Build project
        run: npm run build

      - name: 📏 Analyze bundle size
        run: |
          echo "📏 Analyzing bundle size..."
          npx bundlesize
        continue-on-error: true

      - name: 📊 Generate bundle analyzer report
        run: |
          echo "📊 Generating bundle analyzer report..."
          npx webpack-bundle-analyzer build/static/js/*.js --mode static --report build/bundle-report.html
        continue-on-error: true

      - name: 📈 Calculate bundle metrics
        run: |
          echo "📈 Calculating bundle metrics..."

          # Get main bundle size
          MAIN_BUNDLE_SIZE=$(find build/static/js -name "main.*.js" -exec stat -c%s {} \; | head -1)
          MAIN_BUNDLE_SIZE_KB=$((MAIN_BUNDLE_SIZE / 1024))

          # Get total bundle size
          TOTAL_SIZE=$(du -sb build/ | cut -f1)
          TOTAL_SIZE_KB=$((TOTAL_SIZE / 1024))

          echo "Main bundle size: ${MAIN_BUNDLE_SIZE_KB}KB"
          echo "Total build size: ${TOTAL_SIZE_KB}KB"

          # Save metrics to file
          echo "MAIN_BUNDLE_SIZE_KB=${MAIN_BUNDLE_SIZE_KB}" >> $GITHUB_ENV
          echo "TOTAL_SIZE_KB=${TOTAL_SIZE_KB}" >> $GITHUB_ENV

      - name: 📤 Upload bundle analysis
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis-${{ github.sha }}
          path: |
            build/bundle-report.html
            build/static/
          retention-days: 30

  # 🧪 Load Testing
  load-testing:
    name: 🧪 Load Testing
    runs-on: ubuntu-latest
    timeout-minutes: 12
    needs: lighthouse

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🏗️ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline

      - name: 🏗️ Build project
        run: npm run build

      - name: 🚀 Start application
        run: |
          echo "🚀 Starting application for load testing..."
          npx serve -s build -l 3000 &
          sleep 15
          curl -f http://localhost:3000 || exit 1

      - name: 🧪 Run load tests with Artillery
        run: |
          echo "🧪 Running load tests..."
          npm install -g artillery
          artillery quick --count 10 --num 5 http://localhost:3000 > load-test-results.txt
          cat load-test-results.txt
        continue-on-error: true

      - name: 🧪 Run k6 load tests
        run: |
          echo "🧪 Running k6 load tests..."
          docker run --rm -v $(pwd):/scripts loadimpact/k6 run /scripts/load-test.js
        continue-on-error: true

      - name: 📤 Upload load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results-${{ github.sha }}
          path: |
            load-test-results.txt
            k6-results.json
          retention-days: 30

  # 📱 Mobile Performance
  mobile-performance:
    name: 📱 Mobile Performance
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🏗️ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"

      - name: 📦 Install dependencies
        run: npm ci --prefer-offline

      - name: 🏗️ Build project
        run: npm run build

      - name: 🚀 Start application
        run: |
          echo "🚀 Starting application for mobile testing..."
          npx serve -s build -l 3000 &
          sleep 15
          curl -f http://localhost:3000 || exit 1

      - name: 📱 Mobile Lighthouse test
        run: |
          echo "📱 Running mobile Lighthouse test..."
          npx lighthouse http://localhost:3000 --output=json --output-path=./mobile-lighthouse.json --chrome-flags="--headless --user-agent='Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15'"
        continue-on-error: true

      - name: 📱 Mobile performance metrics
        run: |
          echo "📱 Extracting mobile performance metrics..."
          node -e "
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('./mobile-lighthouse.json', 'utf8'));
            const metrics = report.lighthouseResult.audits;
            console.log('Mobile Performance Score:', report.lighthouseResult.categories.performance.score * 100);
            console.log('First Contentful Paint:', metrics['first-contentful-paint'].displayValue);
            console.log('Largest Contentful Paint:', metrics['largest-contentful-paint'].displayValue);
            console.log('Cumulative Layout Shift:', metrics['cumulative-layout-shift'].displayValue);
          "
        continue-on-error: true

  # 📊 Performance Regression Detection
  regression-detection:
    name: 📊 Performance Regression Detection
    runs-on: ubuntu-latest
    needs: [lighthouse, bundle-analysis, load-testing, mobile-performance]
    if: always()

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 📊 Compare performance metrics
        run: |
          echo "📊 Comparing performance metrics with previous runs..."

          # This would typically compare with previous performance data
          # stored in a database or artifact
          echo "Performance comparison completed"
        continue-on-error: true

      - name: 📈 Generate performance report
        run: |
          echo "📈 Generating performance report..."

          # Create performance summary
          cat > performance-summary.md << EOF
          # 📊 Performance Report

          **Date:** $(date)
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ## 🎯 Performance Scores

          | Metric | Score | Status |
          |--------|-------|--------|
          | Lighthouse | TBD | ${{ needs.lighthouse.result }} |
          | Bundle Size | TBD | ${{ needs.bundle-analysis.result }} |
          | Load Testing | TBD | ${{ needs.load-testing.result }} |
          | Mobile | TBD | ${{ needs.mobile-performance.result }} |

          ## 📈 Recommendations

          - Monitor bundle size growth
          - Optimize Core Web Vitals
          - Consider code splitting for large bundles
          - Implement lazy loading for non-critical components

          EOF

          cat performance-summary.md
        continue-on-error: true

  # 🚨 Performance Alerts
  performance-alerts:
    name: 🚨 Performance Alerts
    runs-on: ubuntu-latest
    needs: [lighthouse, bundle-analysis, load-testing, mobile-performance]
    if: always() && (needs.lighthouse.result == 'failure' || needs.bundle-analysis.result == 'failure')

    steps:
      - name: 🚨 Create performance issue
        uses: actions/github-script@v7
        with:
          script: |
            const title = `🚨 Performance Alert - ${new Date().toISOString().split('T')[0]}`;
            const body = `
            ## 🚨 Performance Alert Detected

            **Date:** ${new Date().toISOString()}
            **Workflow:** ${{ github.workflow }}
            **Commit:** ${{ github.sha }}

            ### Failed Performance Checks:
            - Lighthouse: ${{ needs.lighthouse.result }}
            - Bundle Analysis: ${{ needs.bundle-analysis.result }}
            - Load Testing: ${{ needs.load-testing.result }}
            - Mobile Performance: ${{ needs.mobile-performance.result }}

            ### Action Required:
            Please review the performance test results and optimize the application.

            ### Links:
            - [Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            - [Performance Tab](https://github.com/${{ github.repository }}/actions)

            ---
            *This issue was automatically created by the performance monitoring workflow.*
            `;

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['performance', 'optimization', 'automated']
            });

  # 📊 Performance Dashboard
  performance-dashboard:
    name: 📊 Performance Dashboard
    runs-on: ubuntu-latest
    needs:
      [
        lighthouse,
        bundle-analysis,
        load-testing,
        mobile-performance,
        regression-detection,
      ]
    if: always()

    steps:
      - name: 📊 Generate performance summary
        run: |
          echo "## 🚀 Performance Monitoring Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📅 Scan Date: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "### 🔍 Scan Type: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ✅ Performance Checks:" >> $GITHUB_STEP_SUMMARY
          echo "- 📊 Lighthouse: ${{ needs.lighthouse.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- 📏 Bundle Analysis: ${{ needs.bundle-analysis.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- 🧪 Load Testing: ${{ needs.load-testing.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- 📱 Mobile Performance: ${{ needs.mobile-performance.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- 📊 Regression Detection: ${{ needs.regression-detection.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Count successful checks
          SUCCESS_COUNT=0
          if [ "${{ needs.lighthouse.result }}" = "success" ]; then SUCCESS_COUNT=$((SUCCESS_COUNT + 1)); fi
          if [ "${{ needs.bundle-analysis.result }}" = "success" ]; then SUCCESS_COUNT=$((SUCCESS_COUNT + 1)); fi
          if [ "${{ needs.load-testing.result }}" = "success" ]; then SUCCESS_COUNT=$((SUCCESS_COUNT + 1)); fi
          if [ "${{ needs.mobile-performance.result }}" = "success" ]; then SUCCESS_COUNT=$((SUCCESS_COUNT + 1)); fi

          echo "### 📈 Overall Performance Score: $SUCCESS_COUNT/4" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ $SUCCESS_COUNT -eq 4 ]; then
            echo "### ✅ All performance checks passed!" >> $GITHUB_STEP_SUMMARY
          elif [ $SUCCESS_COUNT -ge 3 ]; then
            echo "### ⚠️ Most performance checks passed, review failed ones." >> $GITHUB_STEP_SUMMARY
          else
            echo "### ❌ Multiple performance issues detected, optimization required!" >> $GITHUB_STEP_SUMMARY
          fi
